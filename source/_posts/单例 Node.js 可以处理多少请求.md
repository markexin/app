---
title: 单例 Node.js 可以处理多少请求
tags: node
---

# 单例 Node.js 可以处理多少请求

> 原文：https://javascript.plainenglish.io/how-many-requests-can-handle-a-real-world-nodejs-server-side-application-55da7a2f06f3

## 介绍

当我刚接触 Node.js 时，我想知道我的 Node.js 应用程序有多少请求可以在生产中实际处理（作为一个真实的应用程序）。或者我需要多少个服务器实例来处理特定数量的流量。

去年，我在独角兽公司 PicsArt 的一篇文章中读到了一些对我来说非常有趣的东西。他们每秒处理 40K 请求，后端使用 Node.js。

![-w716](media/16279534330189/16279536518753.jpg)

好吧，40K rps 真的很大，除了后端服务器之外，还取决于其他一些因素。但此刻让我们忘记这些因素，只考虑后端硬件和软件，尤其是 Node.js。

**rps** 

```
TPS（RPS）=业务量/单位时间（10*60，以秒为单位）。
```

## 调研

Fastify 开发者做了一个基准测试，它表明 express.js 每秒可以处理约 15K 请求，vanilla HTTP 模块可以处理 70K rps。

![-w722](media/16279534330189/16279544665083.jpg)

我用 Macbook Pro 15" 2015 试了一下，结果几乎一样。甚至 express.js 的 15K rps 结果听起来也很棒。但是benchmarks 通常是在一个很小的 ​​API 处理程序上进行的，这与现实世界的 API 相去甚远。

那么，怎么让 API 成为“真实世界”？**数据**，**数据传输**，**以及组件之间的交互**。要模拟真实世界的 API，我们必须创建一个与 DB 或其他服务通信的处理程序。

## 实验

这些结果并不重要。在大多数情况下，像 express(15K) 这样经过验证的框架更好，因为，实际上，您不会使用单个实例每秒处理 100K 请求。因此，我为我的基准测试安装了 express.js 并创建了一个具有各种类型操作的小型 API 处理程序，并进行了负载测试。

![](media/16279534330189/16279548399681.jpg)

- 在数据库中写入一个新用户
- 从数据库中获取 20 个用户
- 栅格化 20 个用户的数组
- 将20个用户对象递归转换为camelCase
- 对 20 个用户的数组进行排序
- 还有一些轻量级计算和标准输出

响应大小约为 12KB，每个用户对象看起来像这样。

![](media/16279534330189/16279549710040.jpg)

## 用 AWS RDS 在 Heroku 中使用 Node.js

我在 Heroku 中以 25 美元/月的硬件部署了该应用程序。然后我在不增加平均延迟的情况下尽可能多地发送请求。所以，我的 Node.js 实例能够在 60 秒内处理 31K 请求，这意味着平均每秒 515 个请求。

![](media/16279534330189/16279554273375.jpg)

## 使用 AWS RDS 在 Heroku 中使用 Django

然后，我问如果我尝试使用非单线程技术进行同样的操作会发生什么。我使用等效的处理程序为 Django 应用程序创建了完全相同的条件并将其部署到同一台服务器。结果比 Node.js 差一点，我可以在 60 秒内达到 23K 请求，因此，每秒 389 个请求。

![](media/16279534330189/16279555316101.jpg)

## 带有 AWS RDS 的 AWS EB 上的 Node.js（3 个实例）

然后，我问，如果我的 Node.js 应用程序是一个真正的生产应用程序，并且它部署在 AWS 中，针对特定流量启动并运行会怎样。我选择法兰克福(eu-central-1，对我来说它是最近的，大约3000公里😁)地区的DB和后端服务器。在这个测试中，我使用了3个Node.js实例和AWS负载平衡。我的3个实例能够在10秒内处理19K请求，这意味着每秒1858个请求。然后，我持续加载我的应用，我可以在13分钟内达到150万成功请求，这是令人兴奋的😁。

![](media/16279534330189/16279556113510.jpg)

那么，我们用一个实例处理600rps，我们需要什么来处理每秒40K的请求?假设平台的平均API比测试中大两倍。所以，我需要40000 /(600/2)= 133个实例，在世界各地的不同地点，一个全球性的独角兽应用。

它可以大 3 倍，但也可以使用各种缓存技术、基于事件的通信等来赢得每秒更多的请求，所以我认为大 2 倍是准确的衡量标准。

我想用一个有用的列表来结束这篇文章，其中列出了您在使用或将要使用的应用程序中可能会遇到的一些问题。

## 可能的性能问题

有无数因素会减慢我们的 API。我分离了一些我们可以在大多数 Web 服务器端应用程序中看到的与性能相关的部分。

- 存储或从DB中获取的数据大小。特别是当我们谈到关系数据库时，这一点就更加重要了，因为大数据通常意味着数据库管理系统和DB内存磁盘之间的复杂查询或复杂操作。然而，在所有情况下，字节越多，所需的传输时间就越多。我们还应该记住，在DB中保存文件是一种反模式，相反，我们应该考虑使用对象存储。理想情况下，我们的数据大小不应该超过几十kb，通常是1-20kb。
- 后端服务器与DB服务器之间的物理距离。距离越远，DB接收查询并发送回后台服务器的时间就越长。考虑一个示例，其中我们在美国弗吉尼亚和德国法兰克福有两个后端服务器，但在美国弗吉尼亚只有一个DB服务器。我们的美国用户的请求将被路由到我们的美国后端实例，延迟约为10-40ms，然后从后端(弗吉尼亚)到DB(弗吉尼亚)的延迟为1-5ms。不坏。让我们看看来自德国的用户会发生什么，“用户的设备”-“后台服务器”的延迟将是10 - 20毫秒，但查询数据将需要120 - 130毫秒。如果我们有一个单一的区域应用，理想情况下我们的数据和后端逻辑是相邻的。或者如果我们有一个全球范围的应用程序，我们应该准备好做各种复杂的工程，以获得良好的性能。
- DB 服务器硬件也有很大的影响。如果我们有一个小应用程序，考虑购买更好的硬件来适应我们的流量，否则——“各种复杂的工程材料”。
- DB调用的次数。在真实的API中，我们可以有，比如，几十个单独的DB调用来最终完成任务，除此之外，在那个API中我们还可以有服务调用，每个服务都有自己的“几十个DB调用”。我遇到的一个令人印象深刻的例子是很久以前我加入的一个项目，一个银行业的后端API。在云开发环境中有一个响应时间为9秒的API。这个API下的服务处理程序有300行代码，其中我们可以找到大约30个DB调用和大约10个内部服务调用。当我们的方法是“代码优先”而不是“设计优先”时，通常会发生这种情况。根据我们的业务逻辑，有许多解决方案可以帮助避免这种情况。例如，队列和其他异步措施可以让我们在“后台”处理一些DB调用。为了利用这一点，我们需要将大服务分解为小服务。此外，我们还可以加入查询以减少DB调用的数量。
- hooks。在所有流行的ODM/ orm中，都有一个称为hooks/中间件的特性。有时候，让这个特性处理一些逻辑是非常合适的。有时，特别是在处理批量操作时，我们可能会面临“隐藏的”瓶颈。ODM/ORM插件也需要计算资源，也需要花费时间(例如camelCase/pascal_case转换插件)。挂钩确实很有帮助，但需要仔细考虑我们写的内容和我们写的地方。
- cpu密集型的任务不仅会减慢服务器的运行速度，而且还会让最终用户等待。在Node.js中，许多cpu密集型任务依赖于线程池。尽管它不会阻塞异步IO，但它会使API变慢。例如，用户单击注册并等待线程池散列他/她的密码，顺便说一下，这需要100毫秒。
- 事件循环的瓶颈。在Node.js中，代码的执行依赖于事件循环，所以我们的代码的性能对整个应用程序有直接的影响(因为它是在单个线程上运行的)。例如，使用JSON。解析/stringify会降低api的速度。嵌套循环和递归函数也很危险。当忽略Node.js如何工作时，根据数据大小和应用程序流量，我们可能会遇到问题，我们的应用程序可能不可用。
- 糟糕的基础体系结构。大型基础设施中可能出现的问题不仅仅是单一应用程序中的问题，它们是不同的，有时它们需要复杂的架构解决方案。当我们的基础架构包含许多组件时，糟糕的架构会对我们的api产生巨大的影响，我们的系统将以一种资源效率低下的方式工作，这意味着我们将为原本可以更便宜的东西付出更多。因此，在设计复杂的应用程序时，我们必须考虑特定技术解决的问题，并充分了解备选方案。我们还需要考虑透视图，如果我们在两个月或六个月的时间内，在制作一个特性时，业务需求发生了变化，对每条语句都尽可能地进行猜测。考虑SLA。考虑一下非功能需求，如果流量增加怎么办?随时准备迎接意想不到的高流量，即使有理论说我们必须准备好处理比现在多10倍的流量。
- 组件/硬件/设置。我们在基础架构中创建的组件可能会降低整个平台的运行速度。假设我们使用RabbitMQ。它像任何技术一样有大量的配置和选项。如果我们一开始就遵循标准，那也没关系。但是，随着时间的推移，如果我们做更多的研究，如果我们深入到一个特定的组件，我们意识到我们可以通过做一些设置审查，或通过重构配置或服务的使用来改进我们的基础设施。此外，我们必须根据使用情况扩展组件，以避免在基础设施中产生瓶颈。



